{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61fd455",
   "metadata": {},
   "source": [
    "# How to TFRecord: A Comprehensive Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360918f",
   "metadata": {},
   "source": [
    "**TFRecord** is a versatile binary file format ideal for storing data. Its quick read speeds and streaming capabilities make it perfect for handling large datasets, especially those that cannot be entirely loaded into memory. TFRecords can store a variety of complex data types ranging from images and lists of floats to serialized tensors, thus aligning with the diverse data types encountered in machine learning workflows.\n",
    "\n",
    "Dive deep into the world of TFRecord and understand foundational concepts like:\n",
    "\n",
    "* Serialization: Converting data structures or object states into a storable format.\n",
    "\n",
    "* BytesList: A list of byte strings used in TensorFlow's TFRecords format, essential when storing byte strings or raw content from image files.\n",
    "\n",
    "\n",
    "**Serialization** is the process of converting data structures or object state into a format that can be stored and reconstructed later in the same or another computer environment. In the context of TensorFlow, serialization is often used to convert tensors into a binary string format that can be written to disk or sent over a network.\n",
    "\n",
    "**BytesList** is a type of list used in TensorFlow's TFRecords format. A `BytesList` is a list of byte strings. When your data is a byte string (such as an image file's raw contents) or a string, you must first convert it into a BytesList in order to store it in a TFRecord.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acf3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.train import BytesList, Int64List, Feature, Features, Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da9e4",
   "metadata": {},
   "source": [
    "# Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d6956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code which generated X, Y and Rec_norm (a parameter I used by my functional api)\n",
    "\n",
    "X = np.ones((10,10,10,10,1))\n",
    "Y = np.ones((10,2))\n",
    "Rec_norm = np.ones((10,1))\n",
    "\n",
    "# Setting the device to CPU.\n",
    "with tf.device('CPU'):\n",
    "    # Convert your data into TensorFlow tensors.\n",
    "    X = tf.convert_to_tensor(X)\n",
    "    Y = tf.convert_to_tensor(Y)\n",
    "    Rec_norm = tf.convert_to_tensor(Rec_norm)\n",
    "\n",
    "# Create TensorFlow Dataset objects from the tensors. \n",
    "features_dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "rec_norm_dataset = tf.data.Dataset.from_tensor_slices(Rec_norm)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(Y)\n",
    "\n",
    "# Create a combined dataset by zipping together the three datasets.\n",
    "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset, rec_norm_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73bec088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label data type before serialization: <dtype: 'float64'>\n",
      "Serialized label data type: <dtype: 'string'>\n",
      "Deserialized label data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Label data type before serialization:\", Y.dtype)\n",
    "serialized_label = tf.io.serialize_tensor(Y)\n",
    "print(\"Serialized label data type:\", serialized_label.dtype)\n",
    "\n",
    "# Deserialize and check the data type\n",
    "deserialized_label = tf.io.parse_tensor(serialized_label, out_type=Y.dtype)\n",
    "print(\"Deserialized label data type:\", deserialized_label.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda5a79",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58558519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a byte feature for your tf.Example. \n",
    "# This is used when your data is a byte or a string.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    # If the value is a Tensor, we get its numpy value.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    # Create and return a Feature with BytesList.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5d87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create an int64 feature for your tf.Example. \n",
    "# This is used when your data is a boolean or integer.\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    # Create and return a Feature with Int64List.\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf62c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_serialize_example(f, l, r):\n",
    "    \"\"\"\n",
    "    Combines the processes of serializing the data and wrapping it in a TensorFlow operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def serialize_content(feature, label, rec_norm):\n",
    "        # Create a dictionary mapping the feature name to the tf.train.Example-compatible data type.\n",
    "        \n",
    "        feature_dict = {\n",
    "          'feature': _bytes_feature(tf.io.serialize_tensor(feature)),\n",
    "          'label': _bytes_feature(tf.io.serialize_tensor(label)),\n",
    "          'rec_norm': _bytes_feature(tf.io.serialize_tensor(rec_norm)),\n",
    "        }\n",
    "\n",
    "        # Create a Features message using tf.train.Example.\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "        \n",
    "        # Return the serialized Example string.\n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    # Using tf.py_function to wrap the serialize_content function\n",
    "    tf_string = tf.py_function(serialize_content, \n",
    "        (f, l, r),  # pass these args to the embedded function.\n",
    "        tf.string   # the return type is `tf.string`.\n",
    "    )\n",
    "    \n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc79ab",
   "metadata": {},
   "source": [
    "## Now using the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389a2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the tf_serialize_example function over the dataset. This applies the function to each example in the dataset.\n",
    "serialized_features_dataset = dataset.map(combined_serialize_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c61260",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e49765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location and filename where the TFRecord will be saved.\n",
    "filename_save = \"E:\\\\\"  \n",
    "\n",
    "writer = tf.io.TFRecordWriter(filename_save+\"Test\"+str(\".tfrecord\"))\n",
    "\n",
    "# Iterate over the serialized dataset and write each example into the TFRecord file.\n",
    "for serialized_example in serialized_features_dataset:\n",
    "    \n",
    "    writer.write(serialized_example.numpy())\n",
    "    \n",
    "# Close the writer to properly save the file.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c4e3b",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1675142",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65533bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    # Create a dictionary describing the features.\n",
    "    feature_description = {\n",
    "      'feature': tf.io.FixedLenFeature([], tf.string),\n",
    "      'label': tf.io.FixedLenFeature([], tf.string),\n",
    "      'rec_norm': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    # Parse the input tf.train.Example proto using the dictionary above.\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    return  (tf.io.parse_tensor(parsed_example['feature'], out_type=tf.float64), \n",
    "            tf.io.parse_tensor(parsed_example['label'], out_type=tf.float64), \n",
    "            tf.io.parse_tensor(parsed_example['rec_norm'], out_type=tf.float64))\n",
    "\n",
    "def set_shapes(x, y, r):\n",
    "    x_shape = (10, 10, 10, 1)\n",
    "    y_shape = (2,)\n",
    "    r_shape = (1,)  \n",
    "    \n",
    "    x.set_shape(x_shape)\n",
    "    y.set_shape(y_shape)\n",
    "    r.set_shape(r_shape)\n",
    "    \n",
    "    return (x,r), y #here x and r are together returned for the functinal api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24312e",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29544462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_class = tf.data.TFRecordDataset(filename_save+\"Test\"+str(\".tfrecord\"))\n",
    "\n",
    "# Parse the datasets.\n",
    "class_dataset = train_dataset_class.map(_parse_function)\n",
    "\n",
    "dataset = tf.data.Dataset.sample_from_datasets([class_dataset])\n",
    "\n",
    "# your dataset creation code\n",
    "\n",
    "dataset = dataset.map(set_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff07088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(2)  # Replace with your desired batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b2a1e",
   "metadata": {},
   "source": [
    "### Additional transformations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7f1d1",
   "metadata": {},
   "source": [
    "#### repeat()\n",
    "\n",
    "The dataset.repeat() method is used to repeat the dataset indefinitely. \n",
    "\n",
    "Without any arguments, this method will cause the dataset to be repeated in an endless cycle, meaning that it will never run out of data. \n",
    "\n",
    "This is particularly useful when training models for several epochs, as it ensures that the model can continue to receive data from the dataset. \n",
    "\n",
    "If you need to repeat the dataset a specific number of times, you can pass an integer argument to repeat(n), where n is the number of repetitions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd1b8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c975b05",
   "metadata": {},
   "source": [
    "#### prefetch(tf.data.AUTOTUNE)\n",
    "The dataset.prefetch(tf.data.AUTOTUNE) method is used to optimize the pipeline's performance. \n",
    "\n",
    "It prefetches a certain number of batches or elements from the dataset, allowing subsequent steps to be processed while the current step is still executing. \n",
    "\n",
    "The tf.data.AUTOTUNE argument allows TensorFlow to automatically determine the optimal number of batches to prefetch, which can significantly improve the efficiency of data feeding, especially when dealing with large datasets or complex transformations. \n",
    "\n",
    "This is crucial for keeping the data pipeline running smoothly and avoiding bottlenecks, thereby improving training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0147a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(tf.data.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36286ec9",
   "metadata": {},
   "source": [
    "#### Simple Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09f1f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "works\n",
      "(2, 10, 10, 10, 1) (2, 1) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(\"works\")\n",
    "    print(x[0].shape,x[1].shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901e8c6",
   "metadata": {},
   "source": [
    "# Usage in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fa1170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, BatchNormalization, Dropout, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed8815b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 10, 10,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 10, 10, 10,   224         ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 10, 10, 10,   1736        ['conv3d[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 5, 5, 5, 8)   0           ['conv3d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 5, 5, 5, 8)  32          ['max_pooling3d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 5, 5, 5, 8)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           32032       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 33)           0           ['dense[0][0]',                  \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 33)          132         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 33)           0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           1088        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32)          128         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32)           0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " visualized_layer (Dense)       (None, 2)            66          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,438\n",
      "Trainable params: 35,292\n",
      "Non-trainable params: 146\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((0, 10,10, 10, 1))\n",
    "pad = 'same'\n",
    "kernels = 8\n",
    "\n",
    "input_img = Input(shape=X.shape[1:])\n",
    "x = Conv3D(kernels, (3,3,3), activation=\"relu\", padding=pad)(input_img)\n",
    "x = Conv3D(kernels, (3,3,3), activation='relu', padding=pad)(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.20)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "input_rec_norm = Input(shape=(1,))\n",
    "\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Concatenate()([x, input_rec_norm])\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.15)(x)\n",
    "\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.15)(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax', name='visualized_layer')(x)\n",
    "\n",
    "model = Model(inputs=[input_img, input_rec_norm], outputs=outputs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"models/Testmode_{val_accuracy:.2f}.model\"  \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4dca61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming full_dataset is your complete dataset\n",
    "\n",
    "# Split the dataset manually\n",
    "train_dataset = dataset.take(4)  # Taking first 8 for training\n",
    "val_dataset = dataset.skip(4)    # Skipping first 8, taking the rest for validation\n",
    "\n",
    "# Then use train_dataset and val_dataset in model.fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a28f3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 7s 100ms/step - loss: 0.9147 - accuracy: 0.3750 - val_loss: 0.7776 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1787 - accuracy: 0.5000 - val_loss: 0.7753 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9711 - accuracy: 0.7500 - val_loss: 0.7529 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6814 - accuracy: 0.5000 - val_loss: 0.7486 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9017 - accuracy: 0.5000 - val_loss: 0.7482 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9585 - accuracy: 0.6250 - val_loss: 0.7563 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7644 - accuracy: 0.3750 - val_loss: 0.7622 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9666 - accuracy: 0.5000 - val_loss: 0.7945 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7881 - accuracy: 0.5000 - val_loss: 0.7962 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5849 - accuracy: 0.6250 - val_loss: 0.8073 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,  # The train dataset\n",
    "    epochs=10,  # Number of epochs to train\n",
    "    steps_per_epoch=4,  # Number of batches to consider as one epoch\n",
    "    validation_data=val_dataset,  # Validation dataset\n",
    "    validation_steps=1,# Number of validation batches to consider for validation metrics\n",
    "    #callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03802ca8",
   "metadata": {},
   "source": [
    "# Additional Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6ef34",
   "metadata": {},
   "source": [
    "# How many data-entries do I have stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47a919",
   "metadata": {},
   "source": [
    "Can take a very long time, depending on how many event you have. Use tqdm to measure the duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "093109ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def count_records(tfrecord_filename):\n",
    "    return sum(1 for _ in tf.data.TFRecordDataset(tfrecord_filename))\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "train_filenames=[filename_save+\"Test\"+str(\".tfrecord\")]\n",
    "\n",
    "tfrecord_files = train_filenames\n",
    "\n",
    "total_records = sum(count_records(tfrecord) for tfrecord in tqdm(tfrecord_files))\n",
    "print(f\"Total number of records: {total_records}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829a434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d24b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class1 =\"E:\\DSNB/\"#All\n",
    "\n",
    "dataset_class1_names=os.listdir(dataset_class1)\n",
    "class1_files=[]\n",
    "for i in dataset_class1_names:\n",
    "    class1_files.append(dataset_class1+i)\n",
    "\n",
    "\n",
    "dataset_class1 =\"E:\\ATMO/\"#All\n",
    "dataset_class1_names=os.listdir(dataset_class1)\n",
    "class2_files=[]\n",
    "for i in dataset_class1_names:\n",
    "    class2_files.append(dataset_class1+i)\n",
    "  \n",
    "    \n",
    "train_split_index_class1 = int(0.85 * len(class1_files))\n",
    "train_split_index_class2 = int(0.85 * len(class2_files))\n",
    "\n",
    "\n",
    "train_filenames_class1 = class1_files[:train_split_index_class1]\n",
    "train_filenames_class2 = class2_files[:train_split_index_class2]\n",
    "validation_filenames_class1 = class1_files[train_split_index_class1:]\n",
    "validation_filenames_class2 = class2_files[train_split_index_class2:]\n",
    "\n",
    "\n",
    "train_dataset_class1 = tf.data.TFRecordDataset(train_filenames_class1)\n",
    "train_dataset_class2 = tf.data.TFRecordDataset(train_filenames_class2)\n",
    "validation_dataset_class1 = tf.data.TFRecordDataset(validation_filenames_class1)\n",
    "validation_dataset_class2 = tf.data.TFRecordDataset(validation_filenames_class2)\n",
    "\n",
    "# Parse the datasets.\n",
    "class1_dataset = train_dataset_class1.map(_parse_function)\n",
    "class2_dataset = train_dataset_class2.map(_parse_function)\n",
    "\n",
    "# Parse the datasets.\n",
    "class1_dataset_val = validation_dataset_class1.map(_parse_function)\n",
    "class2_dataset_val = validation_dataset_class2.map(_parse_function)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.sample_from_datasets([class1_dataset, class2_dataset])\n",
    "val_dataset = tf.data.Dataset.sample_from_datasets([class1_dataset_val, class2_dataset_val])\n",
    "\n",
    "# your dataset creation code\n",
    "\n",
    "dataset = dataset.map(set_shapes)\n",
    "val_dataset = val_dataset.map(set_shapes)\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "# Add any additional transformations you need.\n",
    "dataset = dataset.batch(128)  # Replace with your desired batch size.\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE) \n",
    "\n",
    "# Add any additional transformations you need.\n",
    "val_dataset = val_dataset.batch(128)  # Replace with your desired batch size.\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_22",
   "language": "python",
   "name": "tf_22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
